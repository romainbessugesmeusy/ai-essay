## Imitation as the Essence of Learning

**You too, my human friend, are a stochastic parrot.**

Imitation plays a vital role in shaping our understanding of the world and our ability to communicate effectively. In
this chapter, we'll explore the role of imitation in human and animal learning, language acquisition, and social
behavior. By understanding how imitation shapes our cognitive abilities, and projecting this onto AI systems, we will
try to unweave the general misconception that learning requires a "deeper understanding" of concepts.

### The Role of Imitation in Human and Animal Learning

Imitation is a natural and essential process in developing cognitive and social skills in both humans and animals. From
a young age, humans learn by observing and copying the actions of others. Reproducing the actions of our peers allows us
to acquire new skills, understand social norms, and adapt to our environment. This is not limited to humans. Animals,
too, rely on imitation to learn crucial survival skills, such as foraging, hunting, and avoiding predators.

Research by Tomasello et al. (1993) has shown that imitation is not just a passive process of copying but an active form
of learning that involves combining sensory information, memory, and motor skills. This complex mix of cognitive
processes allows us to improve our abilities, make adjustments based on feedback, and ultimately learn from the act of "
parroting" others.

### AI Systems as Imitators

Large language models (LLMs) are designed to generate human-like text by imitating the patterns and structures found in
the vast amounts of data they are trained on.

At the core of AI language models are weights, tokens, and embeddings.

Tokens correspond to words or sub-words. They constitute the model's vocabulary. Embeddings are the geometrical
addresses of the tokens in a multidimensional space. Weights are the fine parameters learned by the model to
interconnect the tokens. Using a geographical analogy, tokens are the names of the cities, embeddings represent their
GPS coordinates, and weights correspond to the road infrastructure, including highways and connections between cities,
as well as the rules for navigation and elevation.

As the AI model processes the routes of its training data, it learns and adjusts these weights to capture the
relationships and patterns found in the text, allowing it to generate coherent and contextually relevant text. This
process of adjusting weights is known as "learning" and is modeled after our own ability to form connections between
remote concepts and ideas in our minds.

As humans, we can easily represent ideas as interconnected dots. Sky, color, and blue constitute a simple association of
ideas that we can easily picture as a 2D heuristic map. It's not complicated either to represent in our heads these
networks of ideas floating in a 3D space, forming clouds of interconnected dots. In LLMs, these dots exist in several
hundred dimensions at a time.

The giant leap that enabled generative AI was the introduction of the concept of attention. Transformers, the foundation
of LLMs, are a type of neural network architecture that use self-attention mechanisms to process and analyze input data.
In the context of language models, transformers enable the model to focus on different parts of the input text and
identify patterns across various time scales and contexts. This ability to interrogate the prompt itself to identify the
important parts to concentrate on is the truly transformative aspect of ChatGPT and other text-based generative AIs.
Instead of sequentially processing each word of the given prompt and context, AIs can focus on important parts and
detect the subtext and intentions.

In summary, AI models, with their neural network architectures, are designed to mimic observed patterns and structures
in the data they've been trained on, much like how humans learn from experience. Now, just like humans, these AI models
can focus on important subtexts and underlying intentions, similar to how a student succeeds by understanding not only
the content of a question but also the "why" behind the way it was asked. This ability to discern deeper meaning and
context enables AI models to generate more coherent and relevant responses, mirroring human-like understanding and
reasoning.

### Language Acquisition and AI Models: A Comparative Perspective

Language acquisition showcases the power of imitation in human learning. As children, we learn to speak by listening to
and imitating the sounds, words, and sentence structures used by those around us. This process, known as "echoic
imitation" (Kuhl, 2004), helps us practice articulating sounds and words. Gradually, we develop an understanding of
language rules and meanings, enabling us to communicate effectively with others.

AI models like GPT-3 also learn language through imitation. They process vast amounts of linguistic data in order to
replicate the patterns they observe. The more data the AI model is trained with, the more it refines its understanding
of language, generating coherent and contextually relevant text. The interconnected weights and tokens within the model
allow it to form associations that reflect the underlying structure and meaning of the language it has been trained on.

However, people often describe AI models' way of understanding as distinct from human cognition, arguing that
mathematical representations of language are insufficient to capture abstraction and concepts. This distinction is
frequently made by referring to a "deeper understanding" that humans possess. It's undeniable that humans have a unique
ability to engage in higher-level cognitive processes such as reasoning, problem-solving, and empathy. But when it comes
to understanding ideas and concepts, the frontier may not be as clear-cut as we think.

The term "deeper understanding", for example, is a subjective and vague concept that perpetuate the notion of human
superiority in terms of abstraction. Using such expressions might be a way for researchers to soothe their own fears, by
creating a frontier between human and machine understanding. As AI models continue to evolve and improve, it is crucial
to remain open-minded and unbiased in evaluating their abilities in comparison to human cognition.

### Challenging the Notion that AI Systems are Merely "Parrots"

Critics often argue that AI systems, such as LLMs, are just "parrots" that repeat words and phrases without any real
understanding of their meaning. However, this critique fails to recognize the complexity and sophistication of the
learning processes involved in AI language generation.

Just as humans use repetition and imitation to create connections between concepts in our minds (Tomasello, 2003), AI
systems use a similar process to develop their understanding of language. By adjusting the weights and refining the
connections between tokens, AI models can form associations that reflect the underlying structure and meaning of the
language they are trained on (Elman, 1990).

It is essential to recognize that imitation is a fundamental aspect of learning for both humans and AI systems.
Dismissing AI systems as mere parrots overlooks the fact that imitation allows them to capture the intricate
relationships between words and concepts, just as humans do.

Instead of despising AI systems for their imitation-based learning, we should acknowledge that it is through repetition
and imitation that they can create connections between concepts, leading to a internalization of language and the
development of communication skills. By appreciating the role of imitation in AI language generation, we can better
understand the potential of these systems and explore the possibilities they present for the future of AI research and
development.

References

- Elman, J. L. (1990). Finding structure in time. Cognitive Science, 14(2), 179-211.
- Tomasello, M. (2003). Constructing a language: A usage-based theory of language acquisition. Harvard University Press.

---

Next chapter: [Intelligenceâ€™s flywheel: improvisation](chapter2-improvisation.md)
