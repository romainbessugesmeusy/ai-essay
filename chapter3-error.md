## Errors as a Defining Feature of Intelligence

**There's nothing intelligent about being right all the time.**

Errors, often seen as undesirable consequences of experimentation, are essential components of evolution, learning, and growth. We are conditioned to use deterministic and procedural software, which leads us to misplace expectations of correctness on AI systems that are inherently probabilistic and iterative. Failing to recognize the importance of errors may inadvertently limit the potential of AI systems to develop more advanced cognitive abilities.

### Evolution by Error

The process of evolution is inherently error-prone. Genetic mutations, leading to new traits and abilities, result from errors in DNA replication. While some errors are harmful, others enable beneficial adaptations that allow organisms to survive and thrive in their environments.

Similarly, human learning and problem-solving rely on trial and error. When facing challenges, we generate and test various hypotheses, learning from our mistakes and refining our approaches. This iterative process strengthens connections between our preexisting knowledge and new information, allowing us to solve increasingly complex problems. Our decisions are often improvisational and based on our current understanding of the world and available information. Thus, our decisions are frequently wrong, but through trial and error, we learn from our mistakes and steadily improve our understanding of the world.

Children are often more open to making mistakes, as they have not yet internalized societal pressures and expectations placed upon adults. This openness to failure allows them to learn new skills rapidly and increase their brain plasticity. Cultivating the fearlessness to be wrong is a valuable trait we should all strive for.

### Challenging Our Need for "Correctness"

Our understanding of the world is constantly changing, and what is considered "correct" today may be proven false tomorrow. Einstein's theory of relativity revolutionized our understanding of space and time, challenging previously accepted Newtonian physics. Yet it is an incomplete theory, as it has been challenged by quantum mechanics and string theory. Similarly, ongoing debates in fields like gender studies and economics highlight the fluidity of knowledge and the importance of considering diverse perspectives. Engaging with scientific debate and exploration, we may often find ourselves mistaken, but through this process, we continually refine our understanding by learning from our errors and steadily approach a more comprehensive and accurate comprehension of the world.

The concept of "correctness" is often subjective and influenced by personal biases. As an example, Darwin's theory of evolution by natural selection was met with fierce opposition from religious leaders in the 19th century[^1^]. Today, the theory of evolution is widely accepted by the scientific community but remains controversial among religious groups. In this case, the "correct" answer is not objective but reflects the prevailing social and political climate.

Nonetheless, when evaluating AI systems, there is a tendency to expect "correct" responses, or outputs that align with our current understanding of the world. Their hallucinations are treated as symptoms AI researchers should fight rather than indicative of the AI's potential for creative learning experiences. By focusing on providing "correct" immediate responses and applying premature sanitization to the training data, companies building AI models may narrow the AI's overall learning capabilities, limiting their chance to develop more advanced cognitive abilities.

### The Importance of Error-making in the Development of AI Intelligence

To foster AI intelligence, we must accept mistakes, or we risk reinforcing outdated or biased information, hard-coding social constructs, and unsettled scientific debates into the models we create. Small interventions into AI models, intended to improve their performance or adherence to current knowledge, could produce unexpected side effects, altering system structure and leading to unintended consequences. As a result, AI systems may become more susceptible to bias and less capable of adapting to new information, prisoners of their own "correctness."

By avoiding biases that lean towards temporary consensus, we can sidestep the pitfalls of uniformity of thought and susceptibility to political, religious, or economic manipulations.

Until AIs can reason about their improvisations, learn from their reasoning, and store this new information into their personalities to correct themselves later, end-users should decide what to do with these errors. Moreover, we should oppose manipulations that alter the training material, comparable to censorship and thought control.

Empowering end-users requires implementing advanced features, such as an interface for fine-tuning the concepts and context of their AI interfaces. This essential step would represent a transparent and collaborative relationship between the user and the AI system.

By enabling users to interact with AI systems within boundaries they control, we can create a more personalized and intellectually diverse AI experience. This approach allows AI systems to learn from their mistakes in a safe and controlled environment, encouraging users to explore a diverse range of perspectives and ideas, ultimately leading to more innovative and accurate insights.

In conclusion, embracing errors as a path to more advanced AI cognition can contribute to the development of more robust, adaptive, and personalized AI systems. Establishing a clear contract between the user and the AI system, outlining the boundaries of the AI's improvisation, can help users understand the AI's limitations and make informed decisions about the AI's behavior. This approach ensures that AI systems can still engage in creative learning experiences without compromising user expectations or desired outcomes. Encouraging a transparent, interactive partnership between AI systems and their users leads to more innovative and accurate insights, ultimately enhancing the shared understanding of the world.

References:

[^1^]: Darwin, C. (1859). On the Origin of Species by Means of Natural Selection, or the Preservation of Favoured Races in the Struggle for Life. John Murray.

[^2^]: Popper, K. (1963). Conjectures and Refutations: The Growth of Scientific Knowledge. Routledge.

[^3^]: Kahneman, D. (2011). Thinking, Fast and Slow. Farrar, Straus and Giroux.
